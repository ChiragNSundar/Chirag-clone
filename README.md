# ğŸ§  Chirag Clone - Personal Digital Twin

![Version](https://img.shields.io/badge/version-3.0.1-blue.svg)
![Status](https://img.shields.io/badge/status-production--ready-green.svg)
![Coverage](https://img.shields.io/badge/coverage-88%25-green.svg)
![Auth](https://img.shields.io/badge/auth-OAuth2-orange.svg)

**I am Chirag's digital brain.** A continuously learning AI system that evolves to mimic my personality, knowledge, and communication style.

---

## ğŸ› ï¸ Tech Stack

### Frontend

- **Framework**: React 19 + Vite
- **Styling**: Tailwind CSS (Glassmorphism design)
- **Icons**: Lucide React
- **3D Avatar**: Three.js + React Three Fiber
- **Visualization**: Recharts + Web Audio API
- **State/Animations**: Framer Motion
- **PWA**: Vite PWA Plugin (installable, offline-capable)
- **Testing**: Vitest + Playwright E2E

### Backend

- **Framework**: FastAPI (Python 3.11)
- **AI/LLM**: Google Gemini 2.0 Flash (Primary), OpenAI (Fallback)
- **Robustness**: Circuit Breakers + Rate Limiting + Model Fallback
- **Vector DB**: ChromaDB (Local persistence)
- **Real-Time**: WebSockets for Voice & Vision
- **Auth**: OAuth2 (Google) + JWT + Admin Access Control
- **Task Management**: AsyncIO + APScheduler
- **PDF/Web Processing**: PyMuPDF + BeautifulSoup

### Security

- **Protection**: Prompt Guard + Content Security Policy (CSP)
- **Validation**: Pydantic v2 Strict Models

### Desktop Widget

- **Framework**: Electron
- **Features**: Floating window, screen capture (Eye Mode), global shortcuts

### DevOps & Infrastructure

- **Containerization**: Docker + Docker Compose (v2.3)
- **Server**: Uvicorn (ASGI)
- **Environment**: Dotenv (.env) management
- **Linting**: Pre-commit hooks (Black, Prettier, ESLint)
- **Code Quality**: Husky + lint-staged (auto-fix on commit)

---

## âœ¨ Key Features

### ğŸ” Security & Auth (v2.6)

- **OAuth2 Login**: Secure Google social login flow.
- **Admin Access Control**: Training center restricted to authorized admins (`chiragns12@gmail.com`).
- **JWT Authentication**: Stateless, secure interactions.

### ğŸ™ï¸ Duplex Voice (v2.6)

- **Barge-in Support**: Interrupt the bot mid-sentence naturally.
- **VAD Integration**: Intelligent Voice Activity Detection using WebRTC.

### ğŸ›¡ï¸ Production Grade (v2.5)

- **Circuit Breakers**: Prevents cascading failures when APIs (OpenAI/ElevenLabs) are down.
- **Hybrid RAG**: Combines Semantic Search (Vector) + Keyword Search (BM25) with Reciprocal Rank Fusion.
- **Prompt Guard**: 5-level threat detection against prompt injection and jailbreaks.
- **Model Fallback**: Automatic failover (Gemini â†’ GPT-4o â†’ Local Llama) to ensure 24/7 uptime.

### ğŸš€ Frontier Capabilities (v2.9)

- **Voice Cloning Studio**: Clone your own voice directly from the UI (ElevenLabs integration).
- **Agentic Web Browsing**: Bot can autonomously navigate websites, read content, and take screenshots.
- **GraphRAG**: Uses Knowledge Graphs for structured, multi-hop reasoning on your documents.
- **Local Fine-Tuning**: Export your digital twin's "Brain" and fine-tune a local LLM.

### ğŸŒŸ Advanced Intelligence (v2.4)

- **Deep Research**: Autonomous multi-step web research with source citation.
- **Rewind Memory**: Temporal screen recording analysis ("What was I looking at?").
- **Local Voice**: Offline-first TTS/STT with `faster-whisper` and `piper-tts`.
- **Command Palette (âŒ˜K)**: Quick navigation and actions.

### ğŸ™ï¸ Real-Time Voice Conversation (`/chat`)

**NEW in v2.3!** Talk to your clone naturally with ultra-low latency.

- **WebSocket Streaming**: Bidirectional audio streaming for instant responses.
- **Visualizer**: Real-time frequency bars (Orb/Wave modes) reacting to your voice.
- **Interruption**: Speak anytime to interrupt the bot, just like a real call.
- **Turn-taking**: Smart silence detection to know when you've finished speaking.

### ğŸ‘ï¸ Desktop Vision "Eye Mode"

**NEW in v2.3!** Your clone sees what you see.

- **Screen Awareness**: Toggle "Eye Mode" in the desktop widget.
- **Proactive Suggestions**: The bot watches your active window and offers relevant tips.
- **Privacy-First**: Only captures the active window, never the full desktop.

### ğŸ§  Brain Station (`/training`)

**NEW in v2.3!** Central command for knowledge management.

- **Knowledge Graph**: Interactive 3D visualization of your clone's memory.
- **Drag-and-Drop**: Upload PDFs, text files, and markdown notes.
- **URL Ingestion**: Feed it web pages to learn from instantly.
- **Semantic Search**: Find any fact or document with natural language queries.

### ğŸš€ v3.0 Features (New!)

#### ğŸ§  Cognitive Upgrades

- **Notion Sync**: Connect your Notion workspace to the Brain Station for automatic knowledge ingestion.
- **Daily Briefing**: Get morning audio briefings covering your calendar, drafts, and system stats.
- **Memory Garden**: Edit and merge core memories directly.

#### ğŸ™ï¸ Voice & Autopilot

- **Wake Word**: Say "Hey Chirag" to activate listening mode (powered by `openWakeWord`).
- **Calendar Agent**: The bot can now negotiate meeting times, and create/update/delete events.
- **Slack Integration**: Auto-draft replies for DMs and thread mentions.

### ğŸ›ï¸ Training Center

- **Chat Uploads**: Learn from WhatsApp, Instagram, Discord archives.
- **Interactive Training**: "Interview mode" where the bot asks you questions.
- **Journal**: Daily thought recording and reflection.
- **Facts**: Manual entry for key personal details.
- **Export/Import Brain**: Backup and transfer all learned data as portable JSON.

### ğŸ¤– Social Autopilot (`/autopilot`)

Handle your socials while you sleep:

- **Slack**: Auto-drafts professional replies and summarizes threads.
- **Discord/Telegram**: Smart auto-replies to DMs.
- **Twitter/LinkedIn**: Draft tweets and professional replies in your style.
- **Gmail**: Voice-to-email drafting.
- **Review Workflow**: Nothing is posted without your approval.

---

## ğŸ—ï¸ Architecture

### System Overview

```mermaid
graph TD
    User["User (You)"] -->|Web UI| Frontend["Frontend (React + Vite)"]
    User -->|Desktop| Widget["Desktop Widget (Electron)"]
    
    subgraph "Frontend Layer"
        Frontend --> Dashboard["Analytics Dashboard"]
        Frontend --> Training["Training Center + Brain Station"]
        Frontend --> Chat["Voice Chat + Visualizer"]
        Frontend --> Command["Command Palette (âŒ˜K)"]
    end
    
    Widget -->|WebSocket| Backend
    Frontend -->|WebSocket/API| Backend["Backend (FastAPI)"]
    
    subgraph "Backend Architecture"
        Backend --> Middle["Middleware (Security, Rate Limit)"]
        Middle --> Router["Refactored API Routers"]
        
        subgraph "Router Modules"
            Router --> R_Auth["Auth"]
            Router --> R_Chat["Chat"]
            Router --> R_Voice["Voice"]
            Router --> R_Know["Knowledge"]
            Router --> R_Auto["Autopilot"]
            Router --> R_Vis["Vision"]
        end

        subgraph "Services Layer"
            R_Auth --> Auth["Auth Service"]
            R_Chat --> Fallback["Model Fallback (Gemini/OpenAI)"]
            
            R_Know --> RAG["Hybrid RAG Service"]
            RAG --> Chroma["ChromaDB (or Mock)"]
            RAG --> Redis["Redis Cache"]
            
            R_Voice --> Realtime["Realtime Voice Service"]
            R_Auto --> Social["Social Autopilot"]
            R_Vis --> Vision["Vision Service"]
        end
    end
```

### Real-Time Voice Flow

```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend (VoiceChat)
    participant W as WebSocket
    participant S as RealtimeService
    participant L as LLM
    
    U->>F: Speaks (Audio Stream)
    F->>W: Send Audio Chunks
    W->>S: Transcribe Stream (Whisper)
    S->>S: Detect Silence/Turn End
    S->>L: Update Conversation Context
    L-->>S: Generate Token Stream
    S->>W: Send Text + Audio Stream (TTS)
    W->>F: Play Audio + Visualize
    F-->>U: Hear Response
    
    Note over U,F: User can interrupt at any time
```

---

## ğŸš€ Quick Start Guide

### 1. Prerequisites

- Docker Desktop installed
- [Gemini API Key](https://makersuite.google.com/app/apikey)
- [ElevenLabs API Key](https://elevenlabs.io) (for voice)

### 2. Setup & Run (Recommended)

One command to start everything:

```bash
# 1. Clone & Config
git clone https://github.com/ChiragNSundar/Chirag-clone.git
cd Chirag-clone
cp .env.example .env

# 2. Add API Keys to .env
# GEMINI_API_KEY=...
# ELEVENLABS_API_KEY=...

# 3. Install Dependencies
# This script installs both Python and Node.js dependencies automatically
python install_deps.py

# 4. Start Backend (Terminal 1)
cd backend
python3 main.py
# The server will start on http://localhost:8000

# 5. Start Frontend (Terminal 2)
# Open a new terminal window/tab
cd frontend-react
npm run dev
# The app will be available at http://localhost:5173
```

- **Frontend**: <http://localhost:5173>
- **Backend API**: <http://localhost:8000>

### Option 2: Docker Environment (Isolated)

If you prefer running in containers:

```bash
docker-compose up -d --build
```

- **Frontend**: <http://localhost:5173>
- **Backend API**: <http://localhost:8000>

### 3. Desktop Widget (Optional)

For the "Eye Mode" feature:

```bash
cd desktop-widget
npm install
npm start
```

### 4. Running Tests

**Frontend Unit Tests (Vitest):**

```bash
cd frontend-react

# Run all tests once
npm run test:run

# Watch mode (re-run on file changes)
npm run test

# With coverage report
npm run test:run -- --coverage
```

**Backend Tests (Pytest):**

```bash
cd backend

# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_auth.py -v

# With coverage
pytest tests/ --cov=services --cov-report=term-missing
```

**E2E Tests (Playwright):**

```bash
cd frontend-react

# Install Playwright browsers (first time)
npx playwright install

# Run E2E tests
npx playwright test

# Run with UI mode
npx playwright test --ui
```

**Code Quality (Pre-commit):**

```bash
cd frontend-react

# Initialize Husky (first time after clone)
npm run prepare

# Lint check
npm run lint

# Format check
npm run format
```

---

## ğŸ“ Project Structure

```text
Chirag-clone/
â”œâ”€â”€ .env                        # Environment Config (Secrets)
â”œâ”€â”€ .pre-commit-config.yaml     # Linting Config
â”œâ”€â”€ pyproject.toml              # Python Config
â”œâ”€â”€ requirements.txt            # Python Dependencies
â”œâ”€â”€ install_deps.py             # Robust Installer (NEW)
â”œâ”€â”€ docker-compose.yml          # Container Orchestration
â”œâ”€â”€ Dockerfile                  # Production Build Definition
â”œâ”€â”€ CHANGELOG.md                # Project History
â”œâ”€â”€ README.md                   # Documentation
â”œâ”€â”€ testing.md                  # Testing Guide
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI Application Application & Router Registration
â”‚   â”œâ”€â”€ config.py               # Configuration Settings
â”‚   â”œâ”€â”€ gunicorn.conf.py        # Gunicorn Config
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/                 # Modular API Routes (v2.7)
â”‚   â”‚   â”œâ”€â”€ auth.py             # OAuth2 Routes
â”‚   â”‚   â”œâ”€â”€ chat.py             # Chat & Messaging
â”‚   â”‚   â”œâ”€â”€ training.py         # Training Center
â”‚   â”‚   â”œâ”€â”€ dashboard.py        # Analytics & Health
â”‚   â”‚   â”œâ”€â”€ autopilot.py        # Social Bots
â”‚   â”‚   â”œâ”€â”€ voice.py            # Real-time Voice
â”‚   â”‚   â”œâ”€â”€ cognitive.py        # Active Learning
â”‚   â”‚   â”œâ”€â”€ knowledge.py        # RAG & Documents
â”‚   â”‚   â”œâ”€â”€ vision.py           # Eye Mode
â”‚   â”‚   â””â”€â”€ features.py         # Miscellaneous
â”‚   â”‚
â”‚   â”œâ”€â”€ services/               # Business Logic Microservices
â”‚   â”‚   â”œâ”€â”€ accuracy_service.py     # Verification Logic
â”‚   â”‚   â”œâ”€â”€ active_learning_service.py # Proactive Questioning
â”‚   â”‚   â”œâ”€â”€ analytics_service.py    # Dashboard Metrics
â”‚   â”‚   â”œâ”€â”€ async_job_service.py    # Background Tasks
â”‚   â”‚   â”œâ”€â”€ auth_service.py         # OAuth2 & JWT Logic
â”‚   â”‚   â”œâ”€â”€ avatar_service.py       # 3D Avatar Logic
â”‚   â”‚   â”œâ”€â”€ backup_service.py       # Data Backup
â”‚   â”‚   â”œâ”€â”€ cache_service.py        # Redis/Local Cache
â”‚   â”‚   â”œâ”€â”€ calendar_service.py     # Google Calendar Integration
â”‚   â”‚   â”œâ”€â”€ chat_service.py         # Main Conversation Logic
â”‚   â”‚   â”œâ”€â”€ circuit_breaker.py      # Fault Tolerance
â”‚   â”‚   â”œâ”€â”€ conversation_analytics_service.py # Topic/Heatmap Analysis
â”‚   â”‚   â”œâ”€â”€ core_memory_service.py  # Long-term Memory Summarization
â”‚   â”‚   â”œâ”€â”€ creative_service.py     # Dreams/Poems/Stories Engine
â”‚   â”‚   â”œâ”€â”€ deep_research.py        # Autonomous Research Agent
â”‚   â”‚   â”œâ”€â”€ discord_bot_service.py  # Discord Integration
â”‚   â”‚   â”œâ”€â”€ emotion_service.py      # Sentiment Analysis
â”‚   â”‚   â”œâ”€â”€ gmail_bot_service.py    # Gmail Integration
â”‚   â”‚   â”œâ”€â”€ http_pool.py            # Connection Pooling
â”‚   â”‚   â”œâ”€â”€ hybrid_rag.py           # BM25 + Semantic Search
â”‚   â”‚   â”œâ”€â”€ knowledge_service.py    # RAG/Document/Brain Station
â”‚   â”‚   â”œâ”€â”€ learning_service.py     # Training Logic
â”‚   â”‚   â”œâ”€â”€ linkedin_bot_service.py # LinkedIn Integration
â”‚   â”‚   â”œâ”€â”€ llm_service.py          # Gemini/OpenAI Wrapper
â”‚   â”‚   â”œâ”€â”€ logger.py               # Structured Logging
â”‚   â”‚   â”œâ”€â”€ memory_search_service.py # Advanced Vector Search
â”‚   â”‚   â”œâ”€â”€ memory_service.py       # Vector DB Wrapper (Mock supported)
â”‚   â”‚   â”œâ”€â”€ middleware.py           # Legacy Middleware
â”‚   â”‚   â”œâ”€â”€ model_fallback.py       # LLM Cascade Fallback
â”‚   â”‚   â”œâ”€â”€ mood_service.py         # Emotional State
â”‚   â”‚   â”œâ”€â”€ personality_history_service.py # Personality Drift Tracking
â”‚   â”‚   â”œâ”€â”€ personality_service.py  # Identity Management
â”‚   â”‚   â”œâ”€â”€ prompt_guard.py         # Injection Protection
â”‚   â”‚   â”œâ”€â”€ rate_limiter.py         # API Throttling
â”‚   â”‚   â”œâ”€â”€ realtime_voice_service.py # WebSocket Visualizer/Voice
â”‚   â”‚   â”œâ”€â”€ rewind_service.py       # Screen Memory
â”‚   â”‚   â”œâ”€â”€ scheduler_service.py    # Cron Jobs
â”‚   â”‚   â”œâ”€â”€ search_service.py       # Web Search
â”‚   â”‚   â”œâ”€â”€ telegram_bot_service.py # Telegram Integration
â”‚   â”‚   â”œâ”€â”€ thinking_service.py     # Recursive Thinking (CoT)
â”‚   â”‚   â”œâ”€â”€ twitter_bot_service.py  # Twitter/X Integration
â”‚   â”‚   â”œâ”€â”€ vision_service.py       # Image/Screen Analysis
â”‚   â”‚   â”œâ”€â”€ voice_service.py        # TTS/STT (ElevenLabs/Whisper)
â”‚   â”‚   â””â”€â”€ whatsapp_bot_service.py # WhatsApp Integration
â”‚   â”‚
â”‚   â”œâ”€â”€ middleware/             # Middleware Layer
â”‚   â”‚   â””â”€â”€ security.py         # CSP & Sanitization
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # Pydantic Schemas
â”‚   â”‚   â””â”€â”€ validation.py       # Request Validation
â”‚   â”‚
â”‚   â”œâ”€â”€ migrations/             # Database Migrations
â”‚   â”‚   â””â”€â”€ versions/
â”‚   â”‚
â”‚   â”œâ”€â”€ parsers/                # Chat Parsers
â”‚   â”‚   â”œâ”€â”€ discord_parser.py
â”‚   â”‚   â”œâ”€â”€ instagram_parser.py
â”‚   â”‚   â”œâ”€â”€ smart_parser.py     # Heuristic/LLM Parser
â”‚   â”‚   â””â”€â”€ whatsapp_parser.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/                  # Backend Tests
â”‚   â”‚   â”œâ”€â”€ conftest.py         # Test Fixtures
â”‚   â”‚   â”œâ”€â”€ test_auth.py        # Auth & Security Tests
â”‚   â”‚   â”œâ”€â”€ test_circuit_breaker.py
â”‚   â”‚   â”œâ”€â”€ test_deep_research.py
â”‚   â”‚   â”œâ”€â”€ test_hybrid_rag.py  # RAG Logic
â”‚   â”‚   â”œâ”€â”€ test_integration.py # E2E API Tests
â”‚   â”‚   â”œâ”€â”€ test_llm.py         # LLM Wrapper Tests
â”‚   â”‚   â”œâ”€â”€ test_local_voice.py # Offline Voice Tests
â”‚   â”‚   â”œâ”€â”€ test_main.py        # Core Routes
â”‚   â”‚   â”œâ”€â”€ test_parsers.py     # Chat Parsing
â”‚   â”‚   â”œâ”€â”€ test_prompt_guard.py # Security Guardrails
â”‚   â”‚   â”œâ”€â”€ test_rewind.py      # Screen Memory
â”‚   â”‚   â”œâ”€â”€ test_services.py    # Service Logic
â”‚   â”‚   â”œâ”€â”€ test_voice.py       # Realtime Voice
â”‚   â”‚   â””â”€â”€ test_export_import.py # Brain Export/Import (NEW)
â”‚   â””â”€â”€ data/                   # Local Storage (Excluded from Git)
â”‚
â”œâ”€â”€ frontend-react/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ postcss.config.js
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”‚
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.tsx            # React Entry Point
â”‚       â”œâ”€â”€ App.tsx             # Routing & Layout
â”‚       â”œâ”€â”€ index.css           # Global Styles
â”‚       â”‚
â”‚       â”œâ”€â”€ components/         # React Components
â”‚       â”‚   â”œâ”€â”€ AudioVisualizer.tsx # Web Audio API Viz
â”‚       â”‚   â”œâ”€â”€ AutopilotPage.tsx   # Bot Control Dashboard
â”‚       â”‚   â”œâ”€â”€ Avatar3D.tsx        # 3D Avatar with Lip-Sync
â”‚       â”‚   â”œâ”€â”€ ChatInterface.tsx   # Main Chat UI + Avatar
â”‚       â”‚   â”œâ”€â”€ CommandPalette.tsx  # Quick Actions
â”‚       â”‚   â”œâ”€â”€ Dashboard.tsx       # Analytics Home
â”‚       â”‚   â”œâ”€â”€ ErrorBoundary.tsx   # React Error Boundary
â”‚       â”‚   â”œâ”€â”€ Layout.tsx          # Navigation Wrapper
â”‚       â”‚   â”œâ”€â”€ LoginPage.tsx       # Social Login
â”‚       â”‚   â”œâ”€â”€ MemoryGraph.tsx     # Interactive Knowledge Graph
â”‚       â”‚   â”œâ”€â”€ ProfilePage.tsx     # Bot Profile Settings
â”‚       â”‚   â”œâ”€â”€ SettingsPanel.tsx   # Preferences & Theme
â”‚       â”‚   â”œâ”€â”€ Skeleton.tsx        # Loading States
â”‚       â”‚   â”œâ”€â”€ ThinkingBubble.tsx  # CoT Visualization
â”‚       â”‚   â”œâ”€â”€ Toast.tsx           # Notifications
â”‚       â”‚   â”œâ”€â”€ TrainingCenter.tsx  # Brain Station + Training
â”‚       â”‚   â”œâ”€â”€ VoiceChat.tsx       # Live Voice Streaming
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ __tests__/          # Component Tests
â”‚       â”‚   â”‚   â”œâ”€â”€ Dashboard.test.tsx
â”‚       â”‚   â”‚   â”œâ”€â”€ LoginPage.test.tsx
â”‚       â”‚   â”‚   â””â”€â”€ VoiceChat.test.tsx
â”‚       â”‚
â”‚       â”œâ”€â”€ hooks/              # Custom React Hooks
â”‚       â”œâ”€â”€ services/           # Frontend Services (API)
â”‚       â”œâ”€â”€ utils/              # Utilities
â”‚       â””â”€â”€ e2e/                # Playwright Tests
â”‚
â””â”€â”€ desktop-widget/             # Electron App
    â”œâ”€â”€ main.js
    â”œâ”€â”€ preload.js
    â”œâ”€â”€ index.html
    â””â”€â”€ renderer.js
```

## API Reference

### Health & System

- `GET /api/health`: System status, version, and service health checks (supports `?detailed=true`).
- `GET /api/system/metrics`: Cache stats, memory usage, connection pool status.
- `GET /api/profile`: Get the bot's personality profile and stats.

### ğŸ§  Brain Station (Knowledge)

- `GET /api/knowledge/stats`: Knowledge base statistics.
- `GET /api/knowledge/documents`: List indexed documents.
- `POST /api/knowledge/upload`: Upload PDF/TXT/MD files.
- `POST /api/knowledge/text`: Ingest raw text facts.
- `POST /api/knowledge/url`: Ingest content from a URL.
- `POST /api/knowledge/query`: Semantic search against the knowledge base.
- `DELETE /api/knowledge/document/{doc_id}`: Remove a document.

### ğŸ™ï¸ Real-Time Voice

- `GET /api/voice/status`: Check TTS/STT service availability.
- `WS /api/voice/stream`: Bidirectional WebSocket for low-latency voice chat.
- `GET /api/voice/realtime/status/{session_id}`: Check status of a voice session.
- `POST /api/voice/listen`: Upload audio blob for transcription (STT).
- `POST /api/voice/speak`: Generate audio from text (TTS).
- `GET /api/voice/voices`: List available voice models.

### ğŸ‘ï¸ Desktop Vision

- `POST /api/vision/desktop`: "Eye Mode" - Analyze active window content.
- `POST /api/vision/analyze`: General image analysis endpoint.

### ğŸ’¬ Chat & Conversation

- `POST /api/chat/message`: Main conversation endpoint (with memory).
- `GET /api/visualization/graph`: Interactive memory graph data.
- `GET /api/dashboard/stats`: Dashboard analytics.
- `GET /api/analytics/conversations`: Conversation history.
- `GET /api/analytics/topics`: Topic clusters and heatmaps.
- `GET /api/creative/types`: Available creative modes (poems, dreams, etc).
- `POST /api/creative/generate`: Generate creative content.
- `GET /api/creative/prompt`: Get current creative prompt.
- `GET /api/drafts/all`: List all pending drafts from all platforms.
- `GET /api/analytics/detailed`: Detailed system analytics.

### ğŸ§© Cognitive Services

- `GET /api/cognitive/core-memories`: List long-term core memories.
- `POST /api/cognitive/trigger-summarization`: Force memory summarization.
- `GET /api/cognitive/active-learning/suggestions`: Get proactive questions.
- `POST /api/cognitive/active-learning/answer`: Answer a proactive question.
- `GET /api/memory/search`: Vector search debugging.
- `GET /api/memory/stats`: Vector database statistics.
- `GET /api/accuracy/quiz`: Generate a self-test quiz.
- `GET /api/accuracy/stats`: Retrieval accuracy metrics.
- `POST /api/accuracy/submit`: Submit quiz answers.
- `POST /api/personality/snapshot`: Save current personality state.
- `GET /api/personality/history`: Track personality changes over time.
- `GET /api/personality/evolution`: Personality evolution metrics.
- `GET /api/cognitive/learning-stats`: Learning progress statistics.

### ğŸ“… Calendar

- `GET /api/calendar/status`: Calendar integration status.
- `GET /api/calendar/events`: List upcoming events.
- `GET /api/calendar/summary`: Daily briefing summary.

### ğŸ“ Training & Feedback

- `POST /api/training/feedback`: Submit user feedback (thumbs up/down).
- `POST /api/training/auth`: Authenticate for Training Center.
- `POST /api/training/upload/{source}`: Upload chat logs (WhatsApp, Discord, etc).
- `POST /api/training/upload/document`: Upload a single document.
- `POST /api/training/fact`: Add a manual fact.
- `GET /api/training/facts`: List manual facts.
- `DELETE /api/training/facts/{index}`: Remove a manual fact.
- `POST /api/training/example`: Add a few-shot example.
- `POST /api/training/chat`: Chat in training mode (no memory persistence).
- `GET /api/training/chat/prompt`: Get training prompt.
- `DELETE /api/training/reset`: Reset training session.
- `POST /api/training/journal`: Add a journal entry.
- `GET /api/training/export`: Export all learned data as JSON.
- `POST /api/training/import`: Import previously exported data.

### ğŸ¤– Autopilot Agents

- `GET /api/autopilot/status`: Overall system status.
- `GET /api/autopilot/{platform}/status`: Platform-specific status (discord, twitter, etc).
- `POST /api/autopilot/{platform}/start`: Start a platform bot.
- `POST /api/autopilot/{platform}/stop`: Stop a platform bot.
- `POST /api/autopilot/{platform}/settings`: Update bot settings.
- `POST /api/autopilot/{platform}/generate-reply`: Draft a reply for a DM/mention.
- `POST /api/autopilot/{platform}/generate-tweet`: Generate a new post (Twitter/LinkedIn).
- `GET /api/autopilot/logs`: View agent activity logs.

## ï¿½ğŸ›¡ï¸ Security

- **Local RAG**: Your uploaded documents stay on your machine.
- **Ephemeral Vision**: Eye Mode screenshots are analyzed in RAM and discarded instantly.
- **PIN Protection**: Critical training features are locked.

---

**v3.0.0 "Major Feature" Release** - [View Changelog](CHANGELOG.md)
